# LiveVTT TTML Examples

This directory contains example files demonstrating TTML (Timed Text Markup Language) subtitle generation and conversion.

## Example Files

- **sample.ru.vtt** - Russian WebVTT subtitle file
- **sample.en.vtt** - English WebVTT subtitle file (translation)
- **sample.ttml** - Bilingual TTML file combining both languages

## TTML Format Overview

TTML files combine multiple subtitle tracks into a single XML document with proper language tagging. Each subtitle cue contains both languages:

```xml
<p begin="00:00:05.000" end="00:00:08.500">
    <span xml:lang="ru">–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –Ω–∞—à—É –ø—Ä–æ–≥—Ä–∞–º–º—É.</span>
    <span xml:lang="en">Welcome to our program.</span>
</p>
```

## Generating TTML Files

### Option 1: During Archive Transcription (Default Behavior)

TTML generation is **enabled by default**. Simply run archive transcription:

```bash
python src/python/tools/archive_transcriber.py \
    /path/to/archive \
    --progress \
    --workers 4
```

This will generate:
- `video.ru.vtt` (Russian transcription)
- `video.en.vtt` (English translation)
- `video.ttml` (Bilingual TTML) **‚Üê Generated by default**
- `video.smil` (Wowza manifest with TTML reference)

#### Skip TTML Generation

To generate only VTT files without TTML:

```bash
python src/python/tools/archive_transcriber.py \
    /path/to/archive \
    --no-ttml \
    --progress
```

#### Use VTT Files in SMIL

By default, SMIL manifests reference the TTML file. To use individual VTT files instead:

```bash
python src/python/tools/archive_transcriber.py \
    /path/to/archive \
    --vtt-in-smil \
    --progress
```

### Option 2: Convert Existing VTT Files

Use the standalone converter to merge existing WebVTT files:

```bash
# Basic usage
python src/python/tools/vtt_to_ttml.py \
    --vtt_ru sample.ru.vtt \
    --vtt_en sample.en.vtt \
    --output sample.ttml

# With custom tolerance for timestamp alignment
python src/python/tools/vtt_to_ttml.py \
    --vtt_ru sample.ru.vtt \
    --vtt_en sample.en.vtt \
    --output sample.ttml \
    --tolerance 1.5 \
    --verbose

# Different language codes
python src/python/tools/vtt_to_ttml.py \
    --vtt_ru video.es.vtt \
    --vtt_en video.en.vtt \
    --output video.ttml \
    --lang1 es \
    --lang2 en
```

## TTML Structure

The generated TTML files follow W3C TTML1 specification:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<tt xmlns="http://www.w3.org/ns/ttml" xml:lang="ru">
  <body>
    <div>
      <p begin="HH:MM:SS.mmm" end="HH:MM:SS.mmm">
        <span xml:lang="ru">Russian text</span>
        <span xml:lang="en">English text</span>
      </p>
      <!-- More paragraphs... -->
    </div>
  </body>
</tt>
```

### Key Features

1. **Timestamp Alignment**: Cues from both VTT files are aligned by timestamp with configurable tolerance (default ¬±1 second)
2. **Language Tagging**: Each text span includes proper `xml:lang` attribute
3. **UTF-8 Encoding**: Full Unicode support for all languages
4. **W3C Compliant**: Follows TTML1 specification for maximum compatibility

## Testing the Converter

Try converting the example files:

```bash
cd /home/user/livevtt/examples

# Convert the sample files
python ../src/python/tools/vtt_to_ttml.py \
    --vtt_ru sample.ru.vtt \
    --vtt_en sample.en.vtt \
    --output output.ttml \
    --verbose

# Compare output with the reference sample.ttml
diff -u sample.ttml output.ttml
```

## Timestamp Alignment

The converter handles minor timestamp mismatches:

- **Default tolerance**: ¬±1.0 seconds
- **Configurable**: Use `--tolerance` flag to adjust
- **Warnings**: Logs unaligned cues that exceed tolerance

Example with mismatched timestamps:

```
# VTT 1: 00:00:05.000 --> 00:00:07.000
# VTT 2: 00:00:05.300 --> 00:00:07.300
# Result: Aligned (difference < 1s)
```

## Validation

The converter validates:
- VTT file existence and readability
- WEBVTT header presence
- Cue count and alignment quality
- XML structure validity

Warnings are logged for:
- Missing WEBVTT headers
- Unaligned cue pairs
- Significant timestamp mismatches

## Use Cases

1. **Video Streaming**: Bilingual subtitles for multilingual audiences
2. **Accessibility**: Combined subtitles for translation comparison
3. **Archive**: Single file format for bilingual content
4. **Post-Processing**: Easy conversion of existing subtitle pairs

## Dependencies

The TTML functionality requires:
- Python 3.10+
- Standard library only (xml.etree.ElementTree, argparse, etc.)
- No external dependencies for TTML generation

---

## NLLB Translation Examples

This directory also contains example scripts for testing and comparing NLLB-200 translations.

### `test_nllb_translation.py`

Creates a test VTT file with Russian content for testing the NLLB translator.

**Usage:**
```bash
python examples/test_nllb_translation.py
```

This will:
1. Create a temporary directory with a test `*.ru.vtt` file
2. Print the Russian content
3. Show you the command to run the NLLB translator

**Then translate it:**
```bash
# Follow the printed instructions, e.g.:
python src/python/tools/nllb_vtt_translator.py /tmp/nllb_test_XXXXX --verbose
```

---

### `compare_translations.py`

Compare Whisper and NLLB translations side-by-side for quality assessment.

**Usage:**
```bash
# Compare translations in a directory
python examples/compare_translations.py /path/to/directory

# Show more cues
python examples/compare_translations.py /path/to/directory --max-cues 50
```

**Requirements:**
The directory must contain:
- `*.ru.vtt` - Russian source subtitles
- `*.en.vtt` - Whisper translations (from archive_transcriber)
- `*.nllb.en.vtt` - NLLB translations (from nllb_vtt_translator)

**Example workflow:**
```bash
# 1. Find a directory with Whisper translations
cd /path/to/archive/subfolder

# 2. Translate with NLLB
python src/python/tools/nllb_vtt_translator.py . --max-files 1

# 3. Compare translations
python examples/compare_translations.py .
```

**Output example:**
```
================================================================================
Cue #1 [0.0s - 3.0s]
================================================================================

üá∑üá∫ Russian (source):
   –î–æ–±—Ä—ã–π –¥–µ–Ω—å!

ü§ñ Whisper translation:
   Good day!

üåç NLLB-200 translation:
   Good afternoon!
```

### Quality Comparison Tips

When comparing Whisper vs NLLB translations, consider:

1. **Naturalness**: Does it sound like natural English?
2. **Context**: Is the meaning preserved from the original?
3. **Idioms**: Are Russian idioms appropriately translated?
4. **Technical terms**: Are specialized terms correct?
5. **Consistency**: Are terms translated consistently across cues?

### Quick Start with NLLB

```bash
# 1. Install NLLB dependencies (one-time)
poetry install -E nllb

# 2. Create a test file
python examples/test_nllb_translation.py

# 3. Translate it (follow printed instructions)
python src/python/tools/nllb_vtt_translator.py /tmp/nllb_test_XXXXX --verbose

# 4. OR test on real archive data
python src/python/tools/nllb_vtt_translator.py /mnt/vod/srv/storage/transcoded/some-subfolder --max-files 5

# 5. Compare quality
python examples/compare_translations.py /mnt/vod/srv/storage/transcoded/some-subfolder
```

### Model Selection

NLLB-200 offers multiple model sizes:

| Model | Parameters | GPU RAM | Speed | Quality |
|-------|-----------|---------|-------|---------|
| `facebook/nllb-200-distilled-600M` | 600M | ~2GB | Fast | Good |
| `facebook/nllb-200-1.3B` | 1.3B | ~5GB | Medium | Better |
| `facebook/nllb-200-3.3B` | 3.3B | ~13GB | Slow | Best |

**Recommendation**: Start with `distilled-600M` for speed, use `3.3B` for best quality if you have the GPU memory.

```bash
# Use smaller/faster model
python src/python/tools/nllb_vtt_translator.py /path/to/archive \
  --model facebook/nllb-200-distilled-600M

# Use larger/better model
python src/python/tools/nllb_vtt_translator.py /path/to/archive \
  --model facebook/nllb-200-3.3B
```

---

## Further Reading

- [W3C TTML1 Specification](https://www.w3.org/TR/ttml1/)
- [WebVTT Specification](https://www.w3.org/TR/webvtt1/)
- [LiveVTT Documentation](../docs/TOOLS.md)
- [Meta NLLB-200 Model](https://ai.meta.com/research/no-language-left-behind/)
