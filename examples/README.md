# LiveVTT TTML Examples

This directory contains example files demonstrating TTML (Timed Text Markup Language) subtitle generation and conversion.

## Example Files

- **sample.ru.vtt** - Russian WebVTT subtitle file
- **sample.en.vtt** - English WebVTT subtitle file (translation)
- **sample.ttml** - Bilingual TTML file combining both languages

## TTML Format Overview

TTML files combine multiple subtitle tracks into a single XML document with proper language tagging. Each subtitle cue contains both languages:

```xml
<p begin="00:00:05.000" end="00:00:08.500">
    <span xml:lang="ru">–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –Ω–∞—à—É –ø—Ä–æ–≥—Ä–∞–º–º—É.</span>
    <span xml:lang="en">Welcome to our program.</span>
</p>
```

## Generating TTML Files

### Option 1: During Archive Transcription (Default Behavior)

TTML generation is **enabled by default**. Simply run archive transcription:

```bash
python src/python/tools/archive_transcriber.py \
    /path/to/archive \
    --progress \
    --workers 4
```

This will generate:
- `video.ru.vtt` (Russian transcription)
- `video.en.vtt` (English translation)
- `video.ttml` (Bilingual TTML) **‚Üê Generated by default**
- `video.smil` (Wowza manifest with TTML reference)

#### Skip TTML Generation

To generate only VTT files without TTML:

```bash
python src/python/tools/archive_transcriber.py \
    /path/to/archive \
    --no-ttml \
    --progress
```

#### Use VTT Files in SMIL

By default, SMIL manifests reference the TTML file. To use individual VTT files instead:

```bash
python src/python/tools/archive_transcriber.py \
    /path/to/archive \
    --vtt-in-smil \
    --progress
```

### Option 2: Convert Existing VTT Files

Use the standalone converter to merge existing WebVTT files:

```bash
# Basic usage
python src/python/tools/vtt_to_ttml.py \
    --vtt_ru sample.ru.vtt \
    --vtt_en sample.en.vtt \
    --output sample.ttml

# With custom tolerance for timestamp alignment
python src/python/tools/vtt_to_ttml.py \
    --vtt_ru sample.ru.vtt \
    --vtt_en sample.en.vtt \
    --output sample.ttml \
    --tolerance 1.5 \
    --verbose

# Different language codes
python src/python/tools/vtt_to_ttml.py \
    --vtt_ru video.es.vtt \
    --vtt_en video.en.vtt \
    --output video.ttml \
    --lang1 es \
    --lang2 en
```

## TTML Structure

The generated TTML files follow W3C TTML1 specification:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<tt xmlns="http://www.w3.org/ns/ttml" xml:lang="ru">
  <body>
    <div>
      <p begin="HH:MM:SS.mmm" end="HH:MM:SS.mmm">
        <span xml:lang="ru">Russian text</span>
        <span xml:lang="en">English text</span>
      </p>
      <!-- More paragraphs... -->
    </div>
  </body>
</tt>
```

### Key Features

1. **Timestamp Alignment**: Cues from both VTT files are aligned by timestamp with configurable tolerance (default ¬±1 second)
2. **Language Tagging**: Each text span includes proper `xml:lang` attribute
3. **UTF-8 Encoding**: Full Unicode support for all languages
4. **W3C Compliant**: Follows TTML1 specification for maximum compatibility

## Testing the Converter

Try converting the example files:

```bash
cd /home/user/livevtt/examples

# Convert the sample files
python ../src/python/tools/vtt_to_ttml.py \
    --vtt_ru sample.ru.vtt \
    --vtt_en sample.en.vtt \
    --output output.ttml \
    --verbose

# Compare output with the reference sample.ttml
diff -u sample.ttml output.ttml
```

## Timestamp Alignment

The converter handles minor timestamp mismatches:

- **Default tolerance**: ¬±1.0 seconds
- **Configurable**: Use `--tolerance` flag to adjust
- **Warnings**: Logs unaligned cues that exceed tolerance

Example with mismatched timestamps:

```
# VTT 1: 00:00:05.000 --> 00:00:07.000
# VTT 2: 00:00:05.300 --> 00:00:07.300
# Result: Aligned (difference < 1s)
```

## Validation

The converter validates:
- VTT file existence and readability
- WEBVTT header presence
- Cue count and alignment quality
- XML structure validity

Warnings are logged for:
- Missing WEBVTT headers
- Unaligned cue pairs
- Significant timestamp mismatches

## Use Cases

1. **Video Streaming**: Bilingual subtitles for multilingual audiences
2. **Accessibility**: Combined subtitles for translation comparison
3. **Archive**: Single file format for bilingual content
4. **Post-Processing**: Easy conversion of existing subtitle pairs

## Dependencies

The TTML functionality requires:
- Python 3.10+
- Standard library only (xml.etree.ElementTree, argparse, etc.)
- No external dependencies for TTML generation

---

## NLLB Translation Examples

This directory also contains example scripts for testing and comparing NLLB-200 translations.

### `test_nllb_translation.py`

Creates a test VTT file with Russian content for testing the NLLB translator.

**Usage:**
```bash
python examples/test_nllb_translation.py
```

This will:
1. Create a temporary directory with a test `*.ru.vtt` file
2. Print the Russian content
3. Show you the command to run the NLLB translator

**Then translate it:**
```bash
# Follow the printed instructions, e.g.:
python src/python/tools/nllb_vtt_translator.py /tmp/nllb_test_XXXXX --verbose
```

---

### `compare_translations.py`

Compare Whisper, NLLB, LibreTranslate, and Mistral LLM translations side-by-side for quality assessment.

**Usage:**
```bash
# Compare translations in a directory
python examples/compare_translations.py /path/to/directory

# Show more cues
python examples/compare_translations.py /path/to/directory --max-cues 50
```

**Requirements:**
The directory must contain:
- `*.ru.vtt` - Russian source subtitles
- `*.en.vtt` - Whisper translations (from archive_transcriber)
- `*.nllb.en.vtt` - NLLB translations (from nllb_vtt_translator) [optional]
- `*.libretranslate.en.vtt` - LibreTranslate translations (from libretranslate_vtt_translator) [optional]
- `*.mistral.en.vtt` - Mistral LLM translations (from mistral_vtt_translator) [optional]

**Example workflow:**
```bash
# 1. Find a directory with Whisper translations
cd /path/to/archive/subfolder

# 2. Translate with NLLB
python src/python/tools/nllb_vtt_translator.py . --max-files 1

# 3. Translate with LibreTranslate
python src/python/tools/libretranslate_vtt_translator.py . --max-files 1

# 4. Translate with Mistral LLM
python src/python/tools/mistral_vtt_translator.py . \
  --api-url http://localhost:8000/v1/chat/completions \
  --max-files 1

# 5. Compare all translations
python examples/compare_translations.py .
```

**Output example:**
```
================================================================================
Cue #1 [0.0s - 3.0s]
================================================================================

üá∑üá∫ Russian (source):
   –î–æ–±—Ä—ã–π –¥–µ–Ω—å!

ü§ñ Whisper translation:
   Good day!

üåç NLLB-200 translation:
   Good afternoon!

üîÑ LibreTranslate translation:
   Good afternoon!

üß† Mistral LLM translation:
   Good afternoon!
```

### Quality Comparison Tips

When comparing translations, consider:

1. **Naturalness**: Does it sound like natural English?
2. **Context**: Is the meaning preserved from the original?
3. **Idioms**: Are Russian idioms appropriately translated?
4. **Technical terms**: Are specialized terms correct?
5. **Consistency**: Are terms translated consistently across cues?

### Quick Start with NLLB

```bash
# 1. Install NLLB dependencies (one-time)
poetry install -E nllb

# 2. Create a test file
python examples/test_nllb_translation.py

# 3. Translate it (follow printed instructions)
python src/python/tools/nllb_vtt_translator.py /tmp/nllb_test_XXXXX --verbose

# 4. OR test on real archive data
python src/python/tools/nllb_vtt_translator.py /mnt/vod/srv/storage/transcoded/some-subfolder --max-files 5

# 5. Compare quality
python examples/compare_translations.py /mnt/vod/srv/storage/transcoded/some-subfolder
```

### Model Selection

NLLB-200 offers multiple model sizes:

| Model | Parameters | GPU RAM | Speed | Quality |
|-------|-----------|---------|-------|---------|
| `facebook/nllb-200-distilled-600M` | 600M | ~2GB | Fast | Good |
| `facebook/nllb-200-1.3B` | 1.3B | ~5GB | Medium | Better |
| `facebook/nllb-200-3.3B` | 3.3B | ~13GB | Slow | Best |

**Recommendation**: Start with `distilled-600M` for speed, use `3.3B` for best quality if you have the GPU memory.

```bash
# Use smaller/faster model
python src/python/tools/nllb_vtt_translator.py /path/to/archive \
  --model facebook/nllb-200-distilled-600M

# Use larger/better model
python src/python/tools/nllb_vtt_translator.py /path/to/archive \
  --model facebook/nllb-200-3.3B
```

### Quick Start with LibreTranslate

```bash
# 1. No installation needed! (uses HTTP API)

# 2. Translate using public instance (rate-limited)
python src/python/tools/libretranslate_vtt_translator.py /path/to/archive --max-files 5 --progress

# 3. OR self-host LibreTranslate for unlimited translations
docker run -ti --rm -p 5000:5000 libretranslate/libretranslate

# 4. Use your self-hosted instance
python src/python/tools/libretranslate_vtt_translator.py /path/to/archive \
  --api-url http://localhost:5000/translate \
  --max-files 5 \
  --progress

# 5. Compare quality with other translations
python examples/compare_translations.py /path/to/archive
```

### LibreTranslate vs NLLB

| Feature | LibreTranslate | NLLB-200 |
|---------|---------------|----------|
| **Dependencies** | None (HTTP API) | transformers, torch, sentencepiece |
| **GPU Required** | No | Recommended for speed |
| **Installation** | None | `poetry install -E nllb` |
| **Self-hostable** | Yes (Docker) | Yes (local model) |
| **Free tier** | Yes (public API) | Yes (local model) |
| **Translation quality** | Good | Excellent |
| **Speed** | Depends on network | Very fast (GPU) |
| **Best for** | Lightweight, no GPU | Best quality, local processing |

**When to use LibreTranslate:**
- No GPU available
- Don't want to install heavy ML dependencies
- Need API-based translation for distributed systems
- Want self-hosted instance for privacy/unlimited use

**When to use NLLB:**
- Have GPU available
- Need best possible translation quality
- Processing locally without network dependency
- Batch processing large archives

### Quick Start with Mistral LLM

```bash
# 1. No installation needed! (uses HTTP API)

# 2. Option A: Use Mistral API (cloud) - mistral-large-latest for best quality
export MISTRAL_API_KEY=your_api_key_here
python src/python/tools/mistral_vtt_translator.py /path/to/archive \
  --api-url https://api.mistral.ai/v1/chat/completions \
  --api-key $MISTRAL_API_KEY \
  --model mistral-large-latest \
  --max-files 5 \
  --progress

# 2. Option B: Use local inference (vLLM, Ollama, llama.cpp)
# First, start your inference server:
vllm serve mistralai/Mistral-7B-Instruct-v0.2 --host 0.0.0.0 --port 8000
# OR: ollama pull mistral && ollama serve

# Then translate:
python src/python/tools/mistral_vtt_translator.py /path/to/archive \
  --api-url http://localhost:8000/v1/chat/completions \
  --model mistral \
  --max-files 5 \
  --progress

# 3. Compare quality with other translations
python examples/compare_translations.py /path/to/archive
```

### Translation Method Comparison

| Method | Quality | Dependencies | GPU | Self-host | API Cost | Best For |
|--------|---------|--------------|-----|-----------|----------|----------|
| **Whisper** | Good | faster-whisper | Recommended | Yes | Free | Built-in convenience |
| **NLLB-200** | Excellent | transformers, torch | Recommended | Yes | Free | Best translation quality |
| **LibreTranslate** | Good | None (HTTP) | No | Yes (Docker) | Free tier | No GPU, lightweight |
| **Mistral LLM** | Excellent* | None (HTTP) | No** | Yes (vLLM/Ollama) | Paid/Free** | Context-aware, nuanced |

*Default uses `mistral-large-latest` for best quality. Use `--model mistral-small-latest` for faster/cheaper option.
**Mistral can run on CPU with llama.cpp, or use cloud API (paid). Free when self-hosted.

**When to use Mistral:**
- Need context-aware, nuanced translation
- Want customizable prompts for specific domains (broadcast, technical, etc.)
- Have access to Mistral API or can run local LLM inference
- Quality is critical and budget allows (API costs ~$0.001-0.002 per subtitle)

**When NOT to use Mistral:**
- Budget constrained and processing thousands of files (use NLLB or LibreTranslate)
- Need fastest possible speed (use NLLB with GPU)
- Want zero-dependency solution (use LibreTranslate)

---

## Further Reading

- [W3C TTML1 Specification](https://www.w3.org/TR/ttml1/)
- [WebVTT Specification](https://www.w3.org/TR/webvtt1/)
- [LiveVTT Documentation](../docs/TOOLS.md)
- [Meta NLLB-200 Model](https://ai.meta.com/research/no-language-left-behind/)
- [LibreTranslate Project](https://github.com/LibreTranslate/LibreTranslate)
- [Mistral AI](https://mistral.ai/)
- [vLLM Inference Engine](https://github.com/vllm-project/vllm)
- [Ollama](https://ollama.ai/)
